{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91356b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76430f4",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "495540e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.461</td>\n",
       "      <td>0.407</td>\n",
       "      <td>96.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.331</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0.355</td>\n",
       "      <td>106.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.342</td>\n",
       "      <td>92.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0.345</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.344</td>\n",
       "      <td>102.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.365</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.361</td>\n",
       "      <td>112.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.349</td>\n",
       "      <td>103.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.399</td>\n",
       "      <td>110.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FG_PCT  FG3_PCT    PTS\n",
       "23   0.461    0.407   96.2\n",
       "16   0.441    0.331   99.6\n",
       "16   0.478    0.355  106.5\n",
       "10   0.440    0.342   92.6\n",
       "14   0.478    0.345   99.9\n",
       "..     ...      ...    ...\n",
       "6    0.444    0.344  102.3\n",
       "29   0.435    0.365   93.2\n",
       "2    0.475    0.361  112.9\n",
       "28   0.475    0.349  103.6\n",
       "22   0.494    0.399  110.2\n",
       "\n",
       "[517 rows x 3 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "for year in range(1996, 2022):\n",
    "    df = pd.read_csv('Data/' + str(year) + '-' + str(year + 1)[-2:] + '_stats.csv')\n",
    "    df_list.append(df)\n",
    "df_merged = pd.concat(df_list)\n",
    "df_merged[['FG_PCT', 'FG3_PCT', 'PTS']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged[['FG_PCT', 'FG3_PCT', 'PTS']], df_merged['W_PCT_x'], test_size = 0.33, random_state = None)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494cb74",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "99e64fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "99917f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_list = []\n",
    "X_test_list = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df_merged[['REB']], df_merged['W_PCT_x'], test_size = 0.25, random_state=None)\n",
    "X_train_list.append(X_train_1), X_test_list.append(X_test_1), y_train_list.append(y_train_1), y_test_list.append(y_test_1)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(df_merged[['REB']], df_merged['W_PCT_x'], test_size = 0.25, random_state=None)\n",
    "X_train_list.append(X_train_2), X_test_list.append(X_test_2), y_train_list.append(y_train_2), y_test_list.append(y_test_2)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(df_merged[['REB']], df_merged['W_PCT_x'], test_size = 0.25, random_state=None)\n",
    "X_train_list.append(X_train_3), X_test_list.append(X_test_3), y_train_list.append(y_train_3), y_test_list.append(y_test_3)\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(df_merged[['REB']], df_merged['W_PCT_x'], test_size = 0.25, random_state=None)\n",
    "X_train_list.append(X_train_4), X_test_list.append(X_test_4), y_train_list.append(y_train_4), y_test_list.append(y_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7baa0419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg validation accuracy: 0.1531536928607806\n",
      "variance validation accuracuy: 2.256326561517804e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rmse(targets, predictions):\n",
    "    return np.sqrt(np.mean(np.square(targets - predictions)))\n",
    "\n",
    "def Linear_Regression(X_train, X_test, y_train, y_test):\n",
    "    # Create and train model\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Compute loss to evaluate model\n",
    "    loss = rmse(y_test, predictions)\n",
    "    return loss\n",
    "\n",
    "loss = []\n",
    "var_val = 0\n",
    "for i in range(0, 4):\n",
    "    loss.append(Linear_Regression(X_train_list[i], X_test_list[i], y_train_list[i], y_test_list[i]))\n",
    "\n",
    "avg_val_acc = sum(loss)/4\n",
    "print(\"avg validation accuracy: \" + str(avg_val_acc))\n",
    "print(\"variance validation accuracuy: \" + str(np.var(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6259db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a783ebc",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d2e40065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "    \n",
    "input_size = 1\n",
    "hidden_size1 = 31\n",
    "output_size = 1\n",
    "net = Net(input_size, hidden_size1, output_size)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "X = torch.Tensor(X_train_1.values)\n",
    "Y = torch.Tensor(y_train_1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "aae500a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\broha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\broha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: tensor(6.3218e+13, grad_fn=<PowBackward0>)\n",
      "Epoch: 1\n",
      "Loss: tensor(4.3066e+13, grad_fn=<PowBackward0>)\n",
      "Epoch: 2\n",
      "Loss: tensor(2.9338e+13, grad_fn=<PowBackward0>)\n",
      "Epoch: 3\n",
      "Loss: tensor(1.9986e+13, grad_fn=<PowBackward0>)\n",
      "Epoch: 4\n",
      "Loss: tensor(1.3615e+13, grad_fn=<PowBackward0>)\n",
      "Epoch: 5\n",
      "Loss: tensor(9.2751e+12, grad_fn=<PowBackward0>)\n",
      "Epoch: 6\n",
      "Loss: tensor(6.3185e+12, grad_fn=<PowBackward0>)\n",
      "Epoch: 7\n",
      "Loss: tensor(4.3044e+12, grad_fn=<PowBackward0>)\n",
      "Epoch: 8\n",
      "Loss: tensor(2.9323e+12, grad_fn=<PowBackward0>)\n",
      "Epoch: 9\n",
      "Loss: tensor(1.9976e+12, grad_fn=<PowBackward0>)\n",
      "Epoch: 10\n",
      "Loss: tensor(1.3608e+12, grad_fn=<PowBackward0>)\n",
      "Epoch: 11\n",
      "Loss: tensor(9.2702e+11, grad_fn=<PowBackward0>)\n",
      "Epoch: 12\n",
      "Loss: tensor(6.3152e+11, grad_fn=<PowBackward0>)\n",
      "Epoch: 13\n",
      "Loss: tensor(4.3021e+11, grad_fn=<PowBackward0>)\n",
      "Epoch: 14\n",
      "Loss: tensor(2.9307e+11, grad_fn=<PowBackward0>)\n",
      "Epoch: 15\n",
      "Loss: tensor(1.9965e+11, grad_fn=<PowBackward0>)\n",
      "Epoch: 16\n",
      "Loss: tensor(1.3601e+11, grad_fn=<PowBackward0>)\n",
      "Epoch: 17\n",
      "Loss: tensor(9.2654e+10, grad_fn=<PowBackward0>)\n",
      "Epoch: 18\n",
      "Loss: tensor(6.3119e+10, grad_fn=<PowBackward0>)\n",
      "Epoch: 19\n",
      "Loss: tensor(4.2998e+10, grad_fn=<PowBackward0>)\n",
      "Epoch: 20\n",
      "Loss: tensor(2.9292e+10, grad_fn=<PowBackward0>)\n",
      "Epoch: 21\n",
      "Loss: tensor(1.9955e+10, grad_fn=<PowBackward0>)\n",
      "Epoch: 22\n",
      "Loss: tensor(1.3594e+10, grad_fn=<PowBackward0>)\n",
      "Epoch: 23\n",
      "Loss: tensor(9.2605e+09, grad_fn=<PowBackward0>)\n",
      "Epoch: 24\n",
      "Loss: tensor(6.3086e+09, grad_fn=<PowBackward0>)\n",
      "Epoch: 25\n",
      "Loss: tensor(4.2976e+09, grad_fn=<PowBackward0>)\n",
      "Epoch: 26\n",
      "Loss: tensor(2.9277e+09, grad_fn=<PowBackward0>)\n",
      "Epoch: 27\n",
      "Loss: tensor(1.9944e+09, grad_fn=<PowBackward0>)\n",
      "Epoch: 28\n",
      "Loss: tensor(1.3587e+09, grad_fn=<PowBackward0>)\n",
      "Epoch: 29\n",
      "Loss: tensor(9.2557e+08, grad_fn=<PowBackward0>)\n",
      "Epoch: 30\n",
      "Loss: tensor(6.3053e+08, grad_fn=<PowBackward0>)\n",
      "Epoch: 31\n",
      "Loss: tensor(4.2953e+08, grad_fn=<PowBackward0>)\n",
      "Epoch: 32\n",
      "Loss: tensor(2.9261e+08, grad_fn=<PowBackward0>)\n",
      "Epoch: 33\n",
      "Loss: tensor(1.9934e+08, grad_fn=<PowBackward0>)\n",
      "Epoch: 34\n",
      "Loss: tensor(1.3580e+08, grad_fn=<PowBackward0>)\n",
      "Epoch: 35\n",
      "Loss: tensor(92508152., grad_fn=<PowBackward0>)\n",
      "Epoch: 36\n",
      "Loss: tensor(63019580., grad_fn=<PowBackward0>)\n",
      "Epoch: 37\n",
      "Loss: tensor(42930984., grad_fn=<PowBackward0>)\n",
      "Epoch: 38\n",
      "Loss: tensor(29245988., grad_fn=<PowBackward0>)\n",
      "Epoch: 39\n",
      "Loss: tensor(19923320., grad_fn=<PowBackward0>)\n",
      "Epoch: 40\n",
      "Loss: tensor(13572413., grad_fn=<PowBackward0>)\n",
      "Epoch: 41\n",
      "Loss: tensor(9245972., grad_fn=<PowBackward0>)\n",
      "Epoch: 42\n",
      "Loss: tensor(6298657., grad_fn=<PowBackward0>)\n",
      "Epoch: 43\n",
      "Loss: tensor(4290852., grad_fn=<PowBackward0>)\n",
      "Epoch: 44\n",
      "Loss: tensor(2923068., grad_fn=<PowBackward0>)\n",
      "Epoch: 45\n",
      "Loss: tensor(1991289.7500, grad_fn=<PowBackward0>)\n",
      "Epoch: 46\n",
      "Loss: tensor(1356531.5000, grad_fn=<PowBackward0>)\n",
      "Epoch: 47\n",
      "Loss: tensor(924113.5000, grad_fn=<PowBackward0>)\n",
      "Epoch: 48\n",
      "Loss: tensor(629536.1875, grad_fn=<PowBackward0>)\n",
      "Epoch: 49\n",
      "Loss: tensor(428860.4688, grad_fn=<PowBackward0>)\n",
      "Epoch: 50\n",
      "Loss: tensor(292153.7188, grad_fn=<PowBackward0>)\n",
      "Epoch: 51\n",
      "Loss: tensor(199024.6094, grad_fn=<PowBackward0>)\n",
      "Epoch: 52\n",
      "Loss: tensor(135582., grad_fn=<PowBackward0>)\n",
      "Epoch: 53\n",
      "Loss: tensor(92362.8672, grad_fn=<PowBackward0>)\n",
      "Epoch: 54\n",
      "Loss: tensor(62920.5742, grad_fn=<PowBackward0>)\n",
      "Epoch: 55\n",
      "Loss: tensor(42863.5234, grad_fn=<PowBackward0>)\n",
      "Epoch: 56\n",
      "Loss: tensor(29200.0156, grad_fn=<PowBackward0>)\n",
      "Epoch: 57\n",
      "Loss: tensor(19891.9824, grad_fn=<PowBackward0>)\n",
      "Epoch: 58\n",
      "Loss: tensor(13551.0498, grad_fn=<PowBackward0>)\n",
      "Epoch: 59\n",
      "Loss: tensor(9231.3984, grad_fn=<PowBackward0>)\n",
      "Epoch: 60\n",
      "Loss: tensor(6288.7114, grad_fn=<PowBackward0>)\n",
      "Epoch: 61\n",
      "Loss: tensor(4284.0571, grad_fn=<PowBackward0>)\n",
      "Epoch: 62\n",
      "Loss: tensor(2918.4209, grad_fn=<PowBackward0>)\n",
      "Epoch: 63\n",
      "Loss: tensor(1988.1052, grad_fn=<PowBackward0>)\n",
      "Epoch: 64\n",
      "Loss: tensor(1354.3441, grad_fn=<PowBackward0>)\n",
      "Epoch: 65\n",
      "Loss: tensor(922.6051, grad_fn=<PowBackward0>)\n",
      "Epoch: 66\n",
      "Loss: tensor(628.4906, grad_fn=<PowBackward0>)\n",
      "Epoch: 67\n",
      "Loss: tensor(428.1302, grad_fn=<PowBackward0>)\n",
      "Epoch: 68\n",
      "Loss: tensor(291.6382, grad_fn=<PowBackward0>)\n",
      "Epoch: 69\n",
      "Loss: tensor(198.6553, grad_fn=<PowBackward0>)\n",
      "Epoch: 70\n",
      "Loss: tensor(135.3125, grad_fn=<PowBackward0>)\n",
      "Epoch: 71\n",
      "Loss: tensor(92.1612, grad_fn=<PowBackward0>)\n",
      "Epoch: 72\n",
      "Loss: tensor(62.7653, grad_fn=<PowBackward0>)\n",
      "Epoch: 73\n",
      "Loss: tensor(42.7398, grad_fn=<PowBackward0>)\n",
      "Epoch: 74\n",
      "Loss: tensor(29.0980, grad_fn=<PowBackward0>)\n",
      "Epoch: 75\n",
      "Loss: tensor(19.8048, grad_fn=<PowBackward0>)\n",
      "Epoch: 76\n",
      "Loss: tensor(13.4742, grad_fn=<PowBackward0>)\n",
      "Epoch: 77\n",
      "Loss: tensor(9.1619, grad_fn=<PowBackward0>)\n",
      "Epoch: 78\n",
      "Loss: tensor(6.2246, grad_fn=<PowBackward0>)\n",
      "Epoch: 79\n",
      "Loss: tensor(4.2243, grad_fn=<PowBackward0>)\n",
      "Epoch: 80\n",
      "Loss: tensor(2.8626, grad_fn=<PowBackward0>)\n",
      "Epoch: 81\n",
      "Loss: tensor(1.9364, grad_fn=<PowBackward0>)\n",
      "Epoch: 82\n",
      "Loss: tensor(1.3076, grad_fn=<PowBackward0>)\n",
      "Epoch: 83\n",
      "Loss: tensor(0.8824, grad_fn=<PowBackward0>)\n",
      "Epoch: 84\n",
      "Loss: tensor(0.5977, grad_fn=<PowBackward0>)\n",
      "Epoch: 85\n",
      "Loss: tensor(0.4110, grad_fn=<PowBackward0>)\n",
      "Epoch: 86\n",
      "Loss: tensor(0.2940, grad_fn=<PowBackward0>)\n",
      "Epoch: 87\n",
      "Loss: tensor(0.2270, grad_fn=<PowBackward0>)\n",
      "Epoch: 88\n",
      "Loss: tensor(0.1939, grad_fn=<PowBackward0>)\n",
      "Epoch: 89\n",
      "Loss: tensor(0.1808, grad_fn=<PowBackward0>)\n",
      "Epoch: 90\n",
      "Loss: tensor(0.1775, grad_fn=<PowBackward0>)\n",
      "Epoch: 91\n",
      "Loss: tensor(0.1779, grad_fn=<PowBackward0>)\n",
      "Epoch: 92\n",
      "Loss: tensor(0.1795, grad_fn=<PowBackward0>)\n",
      "Epoch: 93\n",
      "Loss: tensor(0.1812, grad_fn=<PowBackward0>)\n",
      "Epoch: 94\n",
      "Loss: tensor(0.1826, grad_fn=<PowBackward0>)\n",
      "Epoch: 95\n",
      "Loss: tensor(0.1836, grad_fn=<PowBackward0>)\n",
      "Epoch: 96\n",
      "Loss: tensor(0.1844, grad_fn=<PowBackward0>)\n",
      "Epoch: 97\n",
      "Loss: tensor(0.1850, grad_fn=<PowBackward0>)\n",
      "Epoch: 98\n",
      "Loss: tensor(0.1854, grad_fn=<PowBackward0>)\n",
      "Epoch: 99\n",
      "Loss: tensor(0.1856, grad_fn=<PowBackward0>)\n",
      "Epoch: 100\n",
      "Loss: tensor(0.1858, grad_fn=<PowBackward0>)\n",
      "Epoch: 101\n",
      "Loss: tensor(0.1860, grad_fn=<PowBackward0>)\n",
      "Epoch: 102\n",
      "Loss: tensor(0.1860, grad_fn=<PowBackward0>)\n",
      "Epoch: 103\n",
      "Loss: tensor(0.1861, grad_fn=<PowBackward0>)\n",
      "Epoch: 104\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 105\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 106\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 107\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 108\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 109\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 110\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 111\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 112\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 113\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 114\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 115\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 116\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 117\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 118\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 119\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 120\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 121\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 122\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 123\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 124\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 125\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 126\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 127\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 128\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 129\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 130\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 131\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 132\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 133\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 134\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 135\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 136\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 137\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 138\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 139\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 140\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 141\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 142\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 143\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 144\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 145\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 146\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 147\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 148\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 149\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 151\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 152\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 153\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 154\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 155\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 156\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 157\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 158\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 159\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 160\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 161\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 162\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 163\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 164\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 165\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 166\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 167\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 168\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 169\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 170\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 171\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 172\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 173\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 174\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 175\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 176\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 177\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 178\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 179\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 180\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 181\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 182\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 183\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 184\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 185\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 186\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 187\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 188\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 189\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 190\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 191\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 192\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 193\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 194\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 195\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 196\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 197\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 198\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 199\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 200\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 201\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 202\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 203\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 204\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 205\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 206\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 207\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 208\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 209\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 210\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 211\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 212\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 213\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 214\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 215\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 216\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 217\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 218\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 219\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 220\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 221\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 222\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 223\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 224\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 225\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 226\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 227\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 228\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 229\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 230\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 231\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 232\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 233\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 234\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 235\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 236\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 237\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 238\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 239\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 240\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 241\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 242\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 243\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 244\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 245\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 246\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 247\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 248\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 249\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 250\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 251\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 252\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 253\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 254\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 255\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 256\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 257\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 258\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 259\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 260\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 261\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 262\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 263\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 264\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 265\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 266\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 267\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 268\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 269\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 270\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 271\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 272\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 273\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 274\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 275\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 276\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 277\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 278\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 279\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 280\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 281\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 282\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 283\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 284\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 285\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 286\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 287\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 288\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 289\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 290\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 291\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 292\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 293\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 294\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 295\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 296\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 297\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 298\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 299\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 300\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 301\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 302\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 303\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 305\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 306\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 307\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 308\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 309\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 310\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 311\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 312\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 313\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 314\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 315\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 316\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 317\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 318\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 319\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 320\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 321\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 322\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 323\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 324\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 325\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 326\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 327\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 328\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 329\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 330\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 331\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 332\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 333\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 334\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 335\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 336\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 337\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 338\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 339\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 340\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 341\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 342\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 343\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 344\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 345\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 346\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 347\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 348\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 349\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 350\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 351\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 352\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 353\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 354\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 355\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 356\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 357\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 358\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 359\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 360\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 361\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 362\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 363\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 364\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 365\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 366\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 367\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 368\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 369\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 370\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 371\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 372\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 373\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 374\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 375\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 376\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 377\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 378\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 379\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 380\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 381\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 382\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 383\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 384\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 385\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 386\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 387\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 388\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 389\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 390\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 391\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 392\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 393\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 394\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 395\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 396\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 397\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 398\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 399\n",
      "Loss: tensor(0.1862, grad_fn=<PowBackward0>)\n",
      "Epoch: 0\n",
      "Loss: tensor(0.1269, grad_fn=<PowBackward0>)\n",
      "Epoch: 1\n",
      "Loss: tensor(0.1270, grad_fn=<PowBackward0>)\n",
      "Epoch: 2\n",
      "Loss: tensor(0.1271, grad_fn=<PowBackward0>)\n",
      "Epoch: 3\n",
      "Loss: tensor(0.1271, grad_fn=<PowBackward0>)\n",
      "Epoch: 4\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\broha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([193])) that is different to the input size (torch.Size([193, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 6\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 7\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 8\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 9\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 10\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 11\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 12\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 13\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 14\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 15\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 16\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 17\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 18\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 19\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 20\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 21\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 22\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 23\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 24\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 25\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 26\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 27\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 28\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 29\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 30\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 31\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 32\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 33\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 34\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 35\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 36\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 37\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 38\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 39\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 40\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 41\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 42\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 43\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 44\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 45\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 46\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 47\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 48\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 49\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 50\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 51\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 52\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 53\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 54\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 55\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 56\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 57\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 58\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 59\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 60\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 61\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 62\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 63\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 64\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 65\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 66\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 67\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 68\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 69\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 70\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 71\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 72\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 73\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 74\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 75\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 76\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 77\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 78\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 79\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 80\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 81\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 82\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 83\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 84\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 85\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 86\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 87\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 88\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 89\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 90\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 91\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 92\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 93\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 94\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 95\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 96\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 97\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 98\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 99\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 100\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 101\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 102\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 103\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 104\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 105\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 106\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 107\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 108\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 109\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 110\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 111\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 112\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 113\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 114\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 115\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 116\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 117\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 118\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 119\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 120\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 121\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 122\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 123\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 124\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 125\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 126\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 127\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 128\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 129\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 130\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 131\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 132\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 133\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 134\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 135\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 136\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 137\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 138\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 139\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 140\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 141\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 142\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 143\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 144\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 145\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 146\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 147\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 148\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 149\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 150\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 151\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 152\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 153\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 154\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 155\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 156\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 158\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 159\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 160\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 161\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 162\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 163\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 164\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 165\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 166\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 167\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 168\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 169\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 170\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 171\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 172\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 173\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 174\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 175\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 176\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 177\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 178\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 179\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 180\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 181\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 182\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 183\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 184\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 185\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 186\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 187\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 188\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 189\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 190\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 191\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 192\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 193\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 194\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 195\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 196\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 197\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 198\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 199\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 200\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 201\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 202\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 203\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 204\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 205\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 206\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 207\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 208\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 209\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 210\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 211\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 212\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 213\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 214\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 215\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 216\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 217\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 218\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 219\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 220\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 221\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 222\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 223\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 224\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 225\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 226\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 227\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 228\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 229\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 230\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 231\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 232\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 233\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 234\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 235\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 236\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 237\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 238\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 239\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 240\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 241\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 242\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 243\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 244\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 245\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 246\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 247\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 248\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 249\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 250\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 251\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 252\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 253\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 254\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 255\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 256\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 257\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 258\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 259\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 260\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 261\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 262\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 263\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 264\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 265\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 266\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 267\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 268\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 269\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 270\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 271\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 272\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 273\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 274\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 275\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 276\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 277\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 278\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 279\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 280\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 281\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 282\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 283\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 284\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 285\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 286\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 287\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 288\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 289\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 290\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 291\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 292\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 293\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 294\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 295\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 296\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 297\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 298\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 299\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 300\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 301\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 302\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 303\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 305\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 306\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 307\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 308\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 309\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 310\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 311\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 312\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 313\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 314\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 315\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 316\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 317\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 318\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 319\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 320\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 321\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 322\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 323\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 324\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 325\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 326\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 327\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 328\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 329\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 330\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 331\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 332\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 333\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 334\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 335\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 336\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 337\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 338\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 339\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 340\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 341\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 342\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 343\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 344\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 345\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 346\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 347\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 348\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 349\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 350\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 351\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 352\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 353\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 354\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 355\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 356\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 357\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 358\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 359\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 360\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 361\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 362\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 363\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 364\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 365\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 366\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 367\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 368\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 369\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 370\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 371\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 372\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 373\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 374\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 375\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 376\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 377\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 378\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 379\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 380\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 381\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 382\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 383\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 384\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 385\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 386\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 387\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 388\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 389\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 390\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 391\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 392\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 393\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 394\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 395\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 396\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 397\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 398\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 399\n",
      "Loss: tensor(0.1272, grad_fn=<PowBackward0>)\n",
      "Epoch: 0\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 1\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 2\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 3\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 4\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 5\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 6\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 7\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 8\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 9\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 10\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 11\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 12\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 13\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 14\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 15\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 16\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 17\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 18\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 19\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 20\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 21\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 22\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 23\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 24\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 25\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 26\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 27\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 28\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 29\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 30\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 31\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 32\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 33\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 34\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 35\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 36\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 37\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 38\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 39\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 40\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 41\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 42\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 43\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 44\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 45\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 46\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 47\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 48\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 49\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 50\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 51\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 52\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 53\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 55\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 56\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 57\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 58\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 59\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 60\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 61\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 62\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 63\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 64\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 65\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 66\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 67\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 68\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 69\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 70\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 71\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 72\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 73\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 74\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 75\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 76\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 77\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 78\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 79\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 80\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 81\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 82\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 83\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 84\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 85\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 86\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 87\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 88\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 89\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 90\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 91\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 92\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 93\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 94\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 95\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 96\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 97\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 98\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 99\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 100\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 101\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 102\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 103\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 104\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 105\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 106\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 107\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 108\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 109\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 110\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 111\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 112\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 113\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 114\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 115\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 116\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 117\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 118\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 119\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 120\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 121\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 122\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 123\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 124\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 125\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 126\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 127\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 128\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 129\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 130\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 131\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 132\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 133\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 134\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 135\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 136\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 137\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 138\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 139\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 140\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 141\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 142\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 143\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 144\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 145\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 146\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 147\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 148\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 149\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 150\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 151\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 152\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 153\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 154\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 155\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 156\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 157\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 158\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 159\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 160\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 161\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 162\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 163\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 164\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 165\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 166\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 167\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 168\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 169\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 170\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 171\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 172\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 173\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 174\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 175\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 176\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 177\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 178\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 179\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 180\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 181\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 182\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 183\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 184\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 185\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 186\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 187\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 188\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 189\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 190\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 191\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 192\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 193\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 194\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 195\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 196\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 197\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 198\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 199\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 200\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 201\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 202\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 203\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 204\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 205\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 207\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 208\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 209\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 210\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 211\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 212\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 213\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 214\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 215\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 216\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 217\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 218\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 219\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 220\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 221\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 222\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 223\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 224\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 225\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 226\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 227\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 228\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 229\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 230\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 231\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 232\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 233\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 234\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 235\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 236\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 237\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 238\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 239\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 240\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 241\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 242\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 243\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 244\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 245\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 246\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 247\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 248\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 249\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 250\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 251\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 252\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 253\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 254\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 255\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 256\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 257\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 258\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 259\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 260\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 261\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 262\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 263\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 264\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 265\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 266\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 267\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 268\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 269\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 270\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 271\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 272\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 273\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 274\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 275\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 276\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 277\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 278\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 279\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 280\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 281\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 282\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 283\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 284\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 285\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 286\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 287\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 288\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 289\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 290\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 291\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 292\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 293\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 294\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 295\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 296\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 297\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 298\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 299\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 300\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 301\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 302\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 303\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 304\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 305\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 306\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 307\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 308\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 309\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 310\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 311\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 312\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 313\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 314\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 315\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 316\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 317\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 318\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 319\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 320\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 321\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 322\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 323\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 324\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 325\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 326\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 327\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 328\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 329\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 330\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 331\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 332\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 333\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 334\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 335\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 336\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 337\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 338\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 339\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 340\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 341\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 342\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 343\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 344\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 345\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 346\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 347\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 348\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 349\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 350\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 351\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 352\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 353\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 354\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 355\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 356\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 358\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 359\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 360\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 361\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 362\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 363\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 364\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 365\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 366\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 367\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 368\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 369\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 370\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 371\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 372\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 373\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 374\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 375\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 376\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 377\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 378\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 379\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 380\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 381\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 382\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 383\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 384\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 385\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 386\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 387\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 388\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 389\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 390\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 391\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 392\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 393\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 394\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 395\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 396\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 397\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 398\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 399\n",
      "Loss: tensor(0.1468, grad_fn=<PowBackward0>)\n",
      "Epoch: 0\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 1\n",
      "Loss: tensor(0.1495, grad_fn=<PowBackward0>)\n",
      "Epoch: 2\n",
      "Loss: tensor(0.1495, grad_fn=<PowBackward0>)\n",
      "Epoch: 3\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 4\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 5\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 6\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 7\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 8\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 9\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 10\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 11\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 12\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 13\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 14\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 15\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 16\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 17\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 18\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 19\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 20\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 21\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 22\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 23\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 24\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 25\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 26\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 27\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 28\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 29\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 30\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 31\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 32\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 33\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 34\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 35\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 36\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 37\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 38\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 39\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 40\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 41\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 42\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 43\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 44\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 45\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 46\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 47\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 48\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 49\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 50\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 51\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 52\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 53\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 54\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 55\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 56\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 57\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 58\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 59\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 60\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 61\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 62\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 63\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 64\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 65\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 66\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 67\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 68\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 69\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 70\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 71\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 72\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 73\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 74\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 75\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 76\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 77\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 78\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 79\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 80\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 81\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 82\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 83\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 84\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 85\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 86\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 87\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 88\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 89\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 90\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 91\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 92\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 93\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 94\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 95\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 96\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 97\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 98\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 99\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 100\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 101\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 102\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 103\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 104\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 105\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 106\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 107\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 109\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 110\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 111\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 112\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 113\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 114\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 115\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 116\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 117\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 118\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 119\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 120\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 121\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 122\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 123\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 124\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 125\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 126\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 127\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 128\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 129\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 130\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 131\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 132\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 133\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 134\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 135\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 136\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 137\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 138\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 139\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 140\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 141\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 142\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 143\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 144\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 145\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 146\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 147\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 148\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 149\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 150\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 151\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 152\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 153\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 154\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 155\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 156\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 157\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 158\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 159\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 160\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 161\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 162\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 163\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 164\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 165\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 166\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 167\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 168\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 169\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 170\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 171\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 172\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 173\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 174\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 175\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 176\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 177\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 178\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 179\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 180\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 181\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 182\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 183\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 184\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 185\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 186\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 187\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 188\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 189\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 190\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 191\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 192\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 193\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 194\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 195\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 196\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 197\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 198\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 199\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 200\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 201\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 202\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 203\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 204\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 205\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 206\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 207\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 208\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 209\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 210\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 211\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 212\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 213\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 214\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 215\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 216\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 217\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 218\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 219\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 220\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 221\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 222\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 223\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 224\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 225\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 226\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 227\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 228\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 229\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 230\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 231\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 232\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 233\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 234\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 235\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 236\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 237\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 238\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 239\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 240\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 241\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 242\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 243\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 244\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 245\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 246\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 247\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 248\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 249\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 250\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 251\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 252\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 253\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 254\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 255\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 256\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 257\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 258\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 260\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 261\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 262\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 263\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 264\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 265\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 266\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 267\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 268\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 269\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 270\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 271\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 272\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 273\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 274\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 275\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 276\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 277\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 278\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 279\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 280\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 281\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 282\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 283\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 284\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 285\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 286\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 287\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 288\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 289\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 290\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 291\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 292\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 293\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 294\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 295\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 296\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 297\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 298\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 299\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 300\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 301\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 302\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 303\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 304\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 305\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 306\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 307\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 308\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 309\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 310\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 311\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 312\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 313\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 314\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 315\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 316\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 317\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 318\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 319\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 320\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 321\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 322\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 323\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 324\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 325\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 326\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 327\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 328\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 329\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 330\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 331\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 332\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 333\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 334\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 335\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 336\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 337\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 338\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 339\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 340\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 341\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 342\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 343\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 344\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 345\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 346\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 347\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 348\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 349\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 350\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 351\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 352\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 353\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 354\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 355\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 356\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 357\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 358\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 359\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 360\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 361\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 362\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 363\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 364\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 365\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 366\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 367\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 368\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 369\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 370\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 371\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 372\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 373\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 374\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 375\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 376\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 377\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 378\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 379\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 380\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 381\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 382\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 383\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 384\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 385\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 386\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 387\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 388\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 389\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 390\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 391\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 392\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 393\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 394\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 395\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 396\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 397\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 398\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "Epoch: 399\n",
      "Loss: tensor(0.1496, grad_fn=<PowBackward0>)\n",
      "avg validation accuracy: 0.15367484465241432\n",
      "variance validation accuracuy: 2.3751509e-05\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 400\n",
    "batch_size = 31\n",
    "for split in range(4):\n",
    "    X_train = X_train_list[split]\n",
    "    y_train = y_train_list[split]\n",
    "    X_test = X_test_list[split]\n",
    "    y_test = y_test_list[split]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "            \n",
    "            # Clear gradients of optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            y_pred = net(torch.Tensor(X_batch.values))\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_fn(y_pred, torch.Tensor(y_batch.values))\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        print(\"Loss: \" + str(loss**(1/2)))\n",
    "    y_pred = net(torch.Tensor(X_test.values))\n",
    "    loss_test = loss_fn(y_pred, torch.Tensor(y_test.values))\n",
    "    losses.append(loss_test.detach().numpy())\n",
    "losses_sqrt = np.sqrt(losses)\n",
    "avg_val_acc = sum(losses_sqrt)/4\n",
    "print(\"avg validation accuracy: \" + str(avg_val_acc))\n",
    "print(\"variance validation accuracuy: \" + str(np.var(losses_sqrt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7aeab1",
   "metadata": {},
   "source": [
    "### Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look through first two sections under Research Experience, and look at real world examples to reformat it\n",
    "# Projects: Look at real world examples for projects, how they format theirs and do the same with yours. \n",
    "# Leadership: Include JIRA, look at other leadership for resume see which intimiates you and include on yours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
